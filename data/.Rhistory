require(devtools)
install.packages("devtools")
require(devtools)
install_version("tm", version = "0.7-1", repos = "http://cran.us.r-project.org")
install.packages("tm", repos="http://R-Forge.R-project.org")
library(tm)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files)) #Corpus是一種文字檔資料格式--文本
# 移除可能有問題的符號
# content_transformer  為內文取代 function
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
install.packages("tm")
library(devtools)
slam_url <- "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
install.packages("tm")
sudo apt-get install r-cran-slam
sudo apt-get install r-cran-slam
install.packages("Zusätzliche R-Pakete installieren")
sudo apt-get install r-cran-slam
install.packages("tm")
install.packages("tm", repos="http://R-Forge.R-project.org")
install.packages("slam")
library(devtools)
slam_url <- "https://cran.r-project.org/src/contrib/Archive/slam/slam_0.1-37.tar.gz"
install_url(slam_url)
install.packages("tm", repos="http://R-Forge.R-project.org")
install.packages("slam", type = "binary")
install.packages("tm", repos="http://R-Forge.R-project.org")
library(tm)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files)) #Corpus是一種文字檔資料格式--文本
# 移除可能有問題的符號
# content_transformer  為內文取代 function
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
# 複製文本中你不要的符號刪除，可寫多行刪除多種符號
docs <- tm_map(docs, toSpace, "文本中你不要的符號貼於此")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
# 語詞詞幹化(stemmization)
# 以英文為例
#https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96
#library(SnowballC)
#確保任何形式的單字只會轉換成相同詞性出現一次
#docs <- tm_map(docs, stemDocument)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
View(freqFrame)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
view()
View()
docs <- Corpus(VectorSource(files)) #Corpus是一種文字檔資料格式--文本
# 移除可能有問題的符號
# content_transformer  為內文取代 function
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
# 複製文本中你不要的符號刪除，可寫多行刪除多種符號
docs <- tm_map(docs, toSpace, "文本中你不要的符號貼於此")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
# 語詞詞幹化(stemmization)
# 以英文為例
#https://zh.wikipedia.org/wiki/%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96
#library(SnowballC)
#確保任何形式的單字只會轉換成相同詞性出現一次
#docs <- tm_map(docs, stemDocument)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
source('~/Documents/Rreview/kp2018.R', encoding = 'UTF-8')
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- read.table("/Users/chiacolate/Documents/Rreview/2014KP.txt")
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP.txt")
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
View(freqFrame)
View(files)
View(jieba_tokenizer)
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
docs <- tm_map(docs, toSpace, "名")
docs <- tm_map(docs, toSpace, "請")
docs <- tm_map(docs, toSpace, "單")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=10,max.words=30,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(4, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
par(family=("Heiti TC Light"))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=10,max.words=30,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(4, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP.txt")
View(docs)
source('~/Documents/Rreview/kp2018.R', encoding = 'UTF-8', echo=TRUE)
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP copy.txt")
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP copy.txt")
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP copy.txt")
warnings()
fileEncoding=
segmentCN("今天一直下雨")  # 測試
install.packages("tm", repos="http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
install.packages("tm", repos = "http://R-Forge.R-project.org")
View(freqFrame)
View(freqFrame)
View(freqFrame)
View(freqFrame)
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP.txt")
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "")
docs <- tm_map(docs, toSpace, "名")
docs <- tm_map(docs, toSpace, "請")
docs <- tm_map(docs, toSpace, "單")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=5,max.words=30,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(4, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
docs <- readLines("/Users/chiacolate/Documents/Rreview/2014KP.txt")
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "")
docs <- tm_map(docs, toSpace, "名")
docs <- tm_map(docs, toSpace, "請")
docs <- tm_map(docs, toSpace, "單")
docs <- tm_map(docs, toSpace, "就")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=5,max.words=30,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(4, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
View(freqFrame)
Sys.setlocale(category = "LC_ALL", locale = "UTF-8")
setwd("~/Downloads/R1072-master/data")
knitr::opts_chunk$set(echo = TRUE)
rrr <- read.csv("data/datata.csv")
View(rrr)
qqq <- read.csv("data/data.csv", header = TRUE) #我定義我的資料叫做qqq，用read.csv讀進來,header是代表說表頭要不要忽略，true是代表說保留我的表頭
View(qqq)
